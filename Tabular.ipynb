{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tabular.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5s2yxW5mrbn5","colab_type":"text"},"source":["## PrepData:\n","\n","Takes in a dataframe and an activity and generates a new column for it, as well as splits one dataframe into train, valid, and test contiguously "]},{"cell_type":"code","metadata":{"id":"10N6P17erXQ5","colab_type":"code","colab":{}},"source":["class PrepData:\n","  def __init__(self, dataframe, activity):\n","    self.dataframe = dataframe\n","    dataframe['Activity'] = activity\n","    self.lenTrain = int(len(dataframe)/100*70)\n","    self.lenValid = self.lenTrain + int(len(dataframe)/100*20)\n","    self.lenTest = self.lenValid + int(len(dataframe)/100*10)\n","    self.train = dataframe.iloc[:self.lenTrain]\n","    self.valid = dataframe.iloc[self.lenTrain:self.lenValid]\n","    self.test = dataframe.iloc[self.lenValid:]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wpz5_T_cr_ps","colab_type":"text"},"source":["## Combine Data\n","Takes in multiple dataframes and appends them to the above train, valid, and test dataframes. Example is for two dataframes, repeat for any amount needed"]},{"cell_type":"code","metadata":{"id":"zXraALPQsC8V","colab_type":"code","colab":{}},"source":["class CombineData:\n","  def __init__(self, df1, df2):\n","    self.train = df1.train.append([df2.train])\n","    self.valid = df1.valid.append([df2.valid])\n","    self.test = df1.test.append([df2.test])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z_C-iTbGsnX-","colab_type":"text"},"source":["## Calculate Hidden Layer Size\n","![alt text](https://i.imgur.com/OaNtCkK.png)\n","\n","Pass in this hidden layer array into the layers parameters"]},{"cell_type":"code","metadata":{"id":"q8tmVUMasztW","colab_type":"code","colab":{}},"source":["def calcHiddenLayer(data, alpha, ip, op, numHiddenLayers):\n","  return [(len(data.train)//(alpha*(ip+op)))//numHiddenLayers]*numHiddenLayers"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EU6D-5NyuKg5","colab_type":"text"},"source":["## Feature Importance\n","Pass in a learner, a list of categorical variables, and a list of continuous variables.\n","Based on https://medium.com/@mp.music93/neural-networks-feature-importance-with-fastai-5c393cf65815"]},{"cell_type":"code","metadata":{"id":"6563NUN0uVcK","colab_type":"code","colab":{}},"source":["def feature_importance(learner, cat_names, cont_names): \n","    loss0=np.array([learner.loss_func(learner.pred_batch(batch=(x,y.to(\"cpu\"))), y.to(\"cpu\")) for x,y in iter(learner.data.valid_dl)]).mean()\n","    fi=dict()\n","    types=[cat_names, cont_names]\n","    for j, t in enumerate(types):\n","      for i, c in enumerate(t):\n","        loss=[]\n","        for x,y in iter(learner.data.valid_dl):\n","          col=x[j][:,i]    #x[0] da hier cat-vars\n","          idx = torch.randperm(col.nelement())\n","          x[j][:,i] = col.view(-1)[idx].view(col.size())\n","          y=y.to('cpu')\n","          loss.append(learner.loss_func(learner.pred_batch(batch=(x,y)), y))\n","        fi[c]=np.array(loss).mean()-loss0\n","    d = sorted(fi.items(), key=lambda kv: kv[1], reverse=True)\n","    return pd.DataFrame({'cols': [l for l, v in d], 'imp': np.log1p([v for l, v in d])})"],"execution_count":0,"outputs":[]}]}