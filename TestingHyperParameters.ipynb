{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HyperParameters.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m87lR9qie31L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "dc707553-9d16-4886-ccbc-30fc1e1df220"
      },
      "source": [
        "!git clone https://github.com/muellerzr/ML_Useful_Functions.git\n",
        "from ML_Useful_Functions.Functions import *"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML_Useful_Functions'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 33 (delta 12), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxR1Oq-2fGp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SaveModelCallback(TrackerCallback):\n",
        "    \"A `TrackerCallback` that saves the model when monitored quantity is best.\"\n",
        "    def __init__(self, learn:Learner, monitor:str='accuracy', mode:str='auto', every:str='improvement', name:str='bestmodel',):\n",
        "        super().__init__(learn, monitor=monitor, mode=mode)\n",
        "        self.every,self.name = every,name\n",
        "        if self.every not in ['improvement', 'epoch']:\n",
        "            warn(f'SaveModel every {self.every} is invalid, falling back to \"improvement\".')\n",
        "            self.every = 'improvement'\n",
        "\n",
        "                 \n",
        "    def jump_to_epoch(self, epoch:int)->None:\n",
        "        try: \n",
        "            self.learn.load(f'{self.name}_{epoch-1}', purge=False)\n",
        "            print(f\"Loaded {self.name}_{epoch-1}\")\n",
        "        except: print(f'Model {self.name}_{epoch-1} not found.')\n",
        "\n",
        "    def on_epoch_end(self, epoch:int, **kwargs:Any)->None:\n",
        "        \"Compare the value monitored to its best score and maybe save the model.\"\n",
        "        if self.every==\"epoch\": self.learn.save(f'{self.name}_{epoch}')\n",
        "        else: #every=\"improvement\"\n",
        "            current = self.get_monitor_value()\n",
        "            if current is not None and self.operator(current, self.best):\n",
        "                #print(f'Better model found at epoch {epoch} with {self.monitor} value: {current}.')\n",
        "                self.best = current\n",
        "                self.learn.save(f'{self.name}')\n",
        "\n",
        "    def on_train_end(self, **kwargs):\n",
        "        \"Load the best model.\"\n",
        "        if self.every==\"improvement\" and (self.learn.path/f'{self.learn.model_dir}/{self.name}.pth').is_file():\n",
        "            self.learn.load(f'{self.name}', purge=False)\n",
        "            current = self.get_monitor_value()\n",
        "            print(float(current))\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg55301IegjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.tabular import *\n",
        "from fastai.callbacks.tracker import *\n",
        "from fastai.utils.mod_display import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DayTd11FevSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.ADULT_SAMPLE)\n",
        "df = pd.read_csv(path/'adult.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwaBmWEdewmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dep_var = 'salary'\n",
        "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
        "cont_names = ['age', 'fnlwgt', 'education-num']\n",
        "procs = [FillMissing, Categorify, Normalize]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yKm02yXex6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = (TabularList.from_df(df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
        "                           .split_by_idx(list(range(800,1000)))\n",
        "                           .label_from_df(cols=dep_var)\n",
        "                           \n",
        "                           .databunch())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRoLwpTqe8LH",
        "colab_type": "text"
      },
      "source": [
        "# Here I want to find the best Alpha value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeB5ICqxffbR",
        "colab_type": "text"
      },
      "source": [
        "i is your initial value you want to modify. Within the learn call, modify what you want to change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YInqPbXqe0RT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "6329f989-e27e-4d53-ac0e-1949c1d3e2dc"
      },
      "source": [
        "i = 1\n",
        "for x in range(10):\n",
        "  learn = tabular_learner(data, layers=calcHiddenLayer(data, i, 2), metrics=accuracy, callback_fns=SaveModelCallback)\n",
        "  if x == 0:\n",
        "    print('Alpha:', i)\n",
        "  else:\n",
        "    print('\\nAlpha:', i)\n",
        "  with progress_disabled_ctx(learn) as learn:\n",
        "    learn.fit_one_cycle(5)\n",
        "  i += 1"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alpha: 1\n",
            "0.8349999785423279\n",
            "\n",
            "Alpha: 2\n",
            "0.8450000286102295\n",
            "\n",
            "Alpha: 3\n",
            "0.8349999785423279\n",
            "\n",
            "Alpha: 4\n",
            "0.8299999833106995\n",
            "\n",
            "Alpha: 5\n",
            "0.8399999737739563\n",
            "\n",
            "Alpha: 6\n",
            "0.8299999833106995\n",
            "\n",
            "Alpha: 7\n",
            "0.8299999833106995\n",
            "\n",
            "Alpha: 8\n",
            "0.8299999833106995\n",
            "\n",
            "Alpha: 9\n",
            "0.8450000286102295\n",
            "\n",
            "Alpha: 10\n",
            "0.8349999785423279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leVbffFrgaWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}